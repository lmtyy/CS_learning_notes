**U-Net** 是 Diffusion Model 的**躯体**。
如果说之前的数学推导是“灵魂（算法）”，那 U-Net 就是真正干活的“肌肉（神经网络）”。

它本来是 2015 年提出来做**医学图像分割**的（比如在一张黑白的 X 光片里把肺抠出来），但因为它结构太优秀了，被 Diffusion 拿来借用了。

我们分三个层面来拆解它。

### 1. 宏观长相：为什么叫 "U" Net？

它的网络结构画出来，就是一个硕大的字母 **"U"**。

这个 "U" 分为三部分：
1.  **左半边（下坡路 / Encoder / 压缩器）**：
    *   图片输入进去，不断地经过卷积（Convolution）和下采样（Downsampling）。
    *   **作用**：不停地把图片变小、变厚。提取特征，忽略细节，看懂大概意思。
    *   比如：$32 \times 32$ 的图 $\to 16 \times 16 \to 8 \times 8 \dots$

2.  **底部（平地 / Bottleneck / 瓶颈层）**：
    *   这是被压缩得最狠的地方，包含了最高级的语义信息。

3.  **右半边（上坡路 / Decoder / 解压器）**：
    *   不断地进行反向卷积（Up-convolution）和上采样（Upsampling）。
    *   **作用**：把特征图重新放大，还原回原来的分辨率。
    *   比如：$8 \times 8 \to 16 \times 16 \to 32 \times 32$。

**最关键的特征：跳跃连接 (Skip Connections)**
这就是图中横着连过去的灰色剪头。
*   **问题**：你在左边把图片压缩得只剩语义了，丢失了很多位置信息和纹理细节。右边还原的时候，细节丢了怎么补？
*   **解决**：直接把左边同一层的特征图**复制、粘贴**到右边对应的层拼起来！
*   **对抗攻击视角**：这非常重要！这意味着输入的微小扰动（Pixel-level）可以通过 Skip Connection **不经过压缩**直接传导到输出端。这可能是 Diffusion 对对抗样本敏感的原因之一。

---

### 2. Diffusion 模型用的 U-Net 有什么特殊？

原版 U-Net 很简单，DDPM 用的版本也就是**“豪华改装版 U-Net”**，加了两个核心装备：

#### A. 时间嵌入 (Time Embedding) —— 告诉模型“现在几点了”
*   **问题**：同一个 U-Net 要负责从 $t=1000$ 到 $t=1$ 的所有去噪任务。
    *   $t=1000$ 时任务很难（全是噪声），需要大刀阔斧地砍。
    *   $t=1$ 时任务很细（微调），需要小心翼翼地修。
    *   模型必须知道当前是第几步，才能决定用多大力度。
*   **做法**：
    *   把数字 $t$ 像 Transformer 做 Positional Encoding 一样，变成一个向量（比如长度 128 的向量）。
    *   把这个向量**加（Add）**或者**乘（Multiply）**到 U-Net 的每一层特征图上。
    *   **这就相当于给每一层卷积层都发了一个“闹钟”。**

#### B. 自注意力机制 (Self-Attention)
*   DDPM 在 $16 \times 16$ 这种比较小的分辨率层级上，加入 Transformer 里的 Attention 模块。
*   **作用**：让左上角的像素能看见右下角的像素。
*   这大大增强了模型生成全局一致图像的能力（不然画出来的猫头和猫身子可能对不上）。

---

### 3. 输入和输出是什么？

这是最容易搞混的。对于 DDPM 的 U-Net：

*   **输入 (Inputs)**：
    1.  **图像张量**：$(B, C, H, W)$，比如一张带噪声的 $32 \times 32$ 的 RGB 图。
    2.  **时间步**：$(B, )$，比如一串数字 `[500, 482, 10, ...]`。
*   **输出 (Output)**：
    1.  **噪声张量**：$(B, C, H, W)$。
    *   注意：输出尺寸**严格等于**输入尺寸。它不是分类网络（输出一个 Label），它是 Pixel-to-Pixel 的任务。

---

### 4. 对抗攻击视角下的 U-Net

既然你要做 Adversarial Attack，这里有几个针针对 U-Net 的攻击点：

1.  **攻击 Skip Connections**：
    由于 Skip Connection 传递高频信息（细节），如果你在输入图像的高频部分（纹理、边缘）加入不可见的扰动，这些扰动会像坐“直通电梯”一样直接破坏输出的噪声预测。

2.  **攻击 Time Embedding**：
    虽然你很难直接改变 $t$，但如果要搞一些 fancy 的攻击，可以思考：同一个扰动 $\delta$ 能不能同时欺骗模型在 $t=100$ 和 $t=500$ 时的判断？
    *   这涉及模型的**时序鲁棒性**。

3.  **巨大的参数量**：
    U-Net 通常参数量很大且计算深。
    *   做 PGD 攻击时，反向传播求梯度的显存消耗是巨大的（通常比分类模型大得多）。
    *   **Tip**：做实验时小心 OOM (Out of Memory)，注意 Batch Size 设小点。

### 总结
你只需要记住：**U-Net 就是一个能把图片缩小再放大、并且能接收时间信号的卷积神经网络。** 它是 Diffusion 必须依赖的那个 $p_\theta$。