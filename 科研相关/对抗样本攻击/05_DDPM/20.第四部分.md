**Section 4: Experiments (实验验证)**

如果说前面三章是在“写推导验算”，这一章就是在“做化学实验”。
作者跑了一堆代码，通过对比实验（Ablation Study）告诉我们：**“我刚才推导的那堆理论里，哪些选择是对的，哪些其实没那么重要。”**

这章虽然没有复杂的公式推导，但全是**工程上的干货**（Tricks & Best Practices）。对于你做科研复现代码、设计攻击实验非常重要。

我们梳理出三个最核心的实验结论：

---

### test 1：模型到底该预测什么？(Section 4.2)
**问题**：我们在 Section 3 里讨论过，模型 $p_\theta$ 有三种选择：
1.  预测上一时刻的图 $\tilde{\mu}$。
2.  预测原图 $x_0$。
3.  预测噪声 $\epsilon$。

**结果**：
作者做了一张表（Table 2），发现 **预测噪声 $\epsilon$ 的效果碾压其他两个。**
*   预测 $x_0$ 最差。
*   预测 $\tilde{\mu}$ 其次。
*   预测 $\epsilon$ 最好（FID 分数最低，FID 越低代表生成的图越真）。

**【对你的科研价值】**
以后你自己在设计 Diffusion 相关的攻击算法时，**不要试图去拟合原图**，那是吃力不讨好的。要顺应模型的本性——去处理**噪声空间**。攻击就是在噪声上做手脚。

---

### test 2：Loss 要不要加权重？(Section 4.2)
**问题**：
按照数学推导（Section 3），每一项 $L_{t-1}$ 前面其实是有一个复杂的系数（权重）的（取决于 $\beta_t$ 的大小）。
理论上，我们应该用带权重的 $L_{vlb}$（变分下界）。
但作者提出了简化版的 $L_{simple}$（也就是不加权重，大家都一样）。

**结果**：
**不加权重的 $L_{simple}$ 反而比“数学上正确”的 $L_{vlb}$ 生成质量更好！**

**【为什么？（重点）】**
作者分析：这其实改变了模型关注的重点。
*   **$t$ 很小的时候（图快画完了）**：只有极微小的噪声，人眼不可见。稍微画错一点，Pixel-level 的误差（NLL）会很大，但人眼看不出来。
*   **$t$ 很大的时候（还在画轮廓）**：这是定图像内容的阶段。
*   **$L_{simple}$ 的作用**：它实际上**降低了**对 $t$ 很小时刻的关注权重，**增加了**对 $t$ 很大时刻（高噪声）的关注。
*   这意味着：**模型更专注于“构图”和“内容生成”，而不是去纠结最后那一点点不可见的像素噪声。**

**【对攻击的启示】**
如果你想攻击图像的**语义内容**（比如让猫变成狗），你应该重点攻击 **$t$ 较大（大噪声）** 的时刻。因为实验证明，那里才是决定图像内容的关键阶段。

---

### test 3：生成质量对比 (Section 4.1)
**指标说明**：
*   **FID (Fréchet Inception Distance)**：衡量生成的图和真图分布有多像。**越低越好**。
*   **IS (Inception Score)**：衡量生成的图够不够清晰、够不够多样。**越高越好**。

**结果**：
*   DDPM 的 FID 达到了 3.17（在 CIFAR-10 数据集上）。
*   这个分数虽然稍微输给最顶级的 GAN（StyleGAN 等），但是**远远超过**了以前所有的概率模型（VAE, Flow-based models）。
*   更重要的是：DDPM **没有 Mode Collapse（模式坍塌）** 问题。GAN 经常生成着生成着就只会画猫不会画狗了，但 DDPM 都能覆盖到。

---

### Section 4 里的其他微小但重要的设置

1.  **网络架构**：
    *   作者使用的是 **U-Net**（一种经典的图像分割网络）。
    *   加上了 **Attention Mechanism（注意力机制）**。
    *   **$t$ 怎么传进去？** 它是像 Position Embedding 一样，变成一个向量加到网络里的。

2.  **数据归一化**：
    *   图片像素值通常是 $[0, 255]$。
    *   作者把它们除以 255 再乘以 2 减 1，强行缩放到 **$[-1, 1]$** 区间。
    *   这主要是为了配合去噪预测的数学性质（因为噪声是 0 均值的）。
    *   *做攻击时注意数据范围，别攻出界了。*

---

### 总结：读这一章是为了不走弯路

如果不看 Section 4，你可能会为了“追求数学严谨”去用 $L_{vlb}$ 训练，或者尝试预测 $\mu$，结果发现模型根本训不出来。

**记住这三句话，这章就算读透了：**
1.  **U-Net** 是标配容器。
2.  **$L_{simple}$** (预测噪声的 MSE) 是最好用的 Loss。
3.  **预测 $\epsilon$** 是最高效的路。

现在，整篇论文的四个核心部分（简介、过程定义、Loss 推导、实验验证）我们都过了一遍。**接下来还有具体的 Section 5 (Conclusion) 也就是结语，或者你想直接聊聊怎么把这些知识点转化为“对抗攻击”的代码思路？**