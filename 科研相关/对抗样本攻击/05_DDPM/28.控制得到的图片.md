这是一个从 **"Toy Demo"** 到 **"ChatGPT for Images"** 的关键跨越。

你之前学的原生 DDPM 确实是**瞎画**。你给它一个随机噪声，它最后变成猫还是狗，全看运气（取决于那个噪声 $x_T$ 落在流形的哪个区域）。

想要控制它（比如指定“我要猫”），我们需要给这个“引力场”加一个**导航信号**。

主要有两种主流方法，从原理上非常直观：

### 方法一：外挂分类器指挥 (Classifier Guidance)
这是 OpenAI 在 2021 年搞出来的由头（Dhariwal & Nichol）。

**原理：**
1.  **雇佣两个人**：
    *   **生成工 (U-Net)**：只负责把图画真（回到流形）。
    *   **监工 (Classifier)**：一个普通的 ResNet 分类器，它能识别当前的图看起来像不像猫。
2.  **工作流程**：
    *   每一步去噪时，生成工说：“我觉得应该往**左**走（为了变清晰）。”
    *   监工看了一眼现在的图，说：“如果要变成猫，梯度的方向显示应该往**上**走。”
    *   **合力**：最终的去噪方向 = **生成工的方向 + 监工的方向 $\times$ 一个权重 ($s$)**。
    *   $$ \nabla_{x_t} \log p(x_t) + s \cdot \nabla_{x_t} \log p(y=\text{猫} | x_t) $$
    *   这个权重 $s$ 就叫 Guidance Scale。$s$ 越大，强行让它变成猫的力度就越大。

**几何直觉：**
*   生成工想把你拉回流形（无论落在猫区还是狗区）。
*   监工在流形上用力把你往“猫的区域”拽。

---

### 方法二：内嵌指令 (Classifier-Free Guidance, CFG) —— **现在的标准配置**
外挂分类器太麻烦了，还要专门练个能识别噪声图的分类器。所以 Google 的研究者（包括 DDPM 的一作 Jonathan Ho）提出了这个目前**统治**该领域的方法。

**原理：**
1.  **改造 U-Net**：
    *   原来的 U-Net 输入是 $(x_t, t)$。
    *   现在的 U-Net 输入变成了 $(x_t, t, c)$。这里的 $c$ 就是 Class Label（"猫"）或者文本提示（"一只坐在草地上的猫"）。
    *   我们把"猫"变成一个向量（Embedding），像时间 $t$ 一样贴到 U-Net 的每一层里。
2.  **训练技巧**：
    *   训练时，有时候把 $c$ 喂进去（告诉它是猫），有时候把 $c$ 设为空（不告诉它是什么，让它瞎猜）。
    *   这样 U-Net 就练就了左右互搏术：既能命题作画，也能自由发挥。
3.  **生成时的数学魔法 (CFG Formula)**：
    *   在生成时，我们让 U-Net 算两次噪声：
        1.  **有条件预测** $\epsilon(x_t, \text{猫})$：朝着猫的方向走。
        2.  **无条件预测** $\epsilon(x_t, \text{空})$：朝着最像真图的方向走。
    *   **最终方向**：
        $$ \epsilon_{final} = \epsilon(x_t, \text{空}) + w \cdot [\epsilon(x_t, \text{猫}) - \epsilon(x_t, \text{空})] $$
    *   **直觉解读**：
        *   $[\epsilon(\text{猫}) - \epsilon(\text{空})]$ 的意思就是：**“这就是有了‘猫’这个命令后多出来的特征！”**
        *   我们把这个“猫特征”放大 $w$ 倍，强行加回去。
        *   这就迫使模型生成的图必须包含极其强烈的猫的特征。

---

### 对抗攻击的视角（科研切入点）

既然有了控制 (Condition)，攻击面就变大了：

1.  **Untargeted Attack on Condition**：
    *   你说“我要猫”。
    *   我攻击：在 Prompt 的 Embedding 上加微小扰动，或者在初始噪声里埋雷。
    *   结果：虽然文字还是“猫”，但 CFG 算出来的那个向量差变得乱七八糟，最后生成了一只四不像。

2.  **Targeted Attack (Prompt Injection in Logic)**：
    *   用户输入：“画一只可爱的兔子”。
    *   攻击目标：让模型实际上去理解成“画一只恐怖的怪兽”。
    *   通过攻击 $c$ 的编码过程，让“兔子”向量在几何空间里被推向“怪兽”向量的区域。

### 总结
这就是怎么控制生成猫：**给向量场加个偏置（Bias）**。
*   要么外挂一个分类器来指路（Classifier Guidance）。
*   要么训练 U-Net 自己能听懂命令，然后把“猫的特征向量”强行放大（Classifier-Free Guidance）。

现在的 Stable Diffusion、DALL-E 3，用的全是第二种逻辑。如果你要攻击现代模型，必须要去读 CFG 的相关论文（*Classifier-Free Diffusion Guidance*, 2022）。