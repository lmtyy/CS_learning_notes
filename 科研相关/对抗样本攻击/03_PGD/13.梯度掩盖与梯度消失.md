这两个概念是**对抗样本防御领域的“照妖镜”**。

在 2018 年之前（Madry 这篇论文真正确立规范之前），有很多论文宣称发明了“能抵御对抗攻击”的新防御方法。但后来 Athalye 等人在 ICML 2018 的著名论文《Obfuscated Gradients Give a False Sense of Security》中指出，这其中 90% 的防御方法都是假的——它们利用的就是 **梯度掩盖 (Gradient Masking)** 或者是 **梯度消失 (Gradient Vanishing)**。

我用大白话加直观的例子为你解释。

---

### 一、 核心逻辑
**攻击者（PGD/FGSM）需要什么？**
攻击者需要一个**正确的导航（梯度 $\nabla_x L$）**。这个梯度就像路标，告诉攻击者：“往左走 Loss 会变大”。

**防御者的“作弊”手段：**
与其把“山峰”铲平（真正的防御），不如**把“路标”拆了或者乱指（梯度掩盖/消失）**。

---

### 二、 梯度掩盖 (Gradient Masking)

这也被称为 **Obfuscated Gradients**（混淆梯度）。

#### 1. 现象
模型实际上并没有变得更鲁棒（那个导致分类错误的对抗样本依然就在旁边），但是模型通过某种操作，让**输入 $x$ 处的梯度变得不可用**。

#### 2. 常见手段（怎么做到的？）
*   **破碎梯度 (Shattered Gradients)**：
    有些防御方法会在前向传播里加一些不可导的操作（比如 `jpeg_compression`，`bit_depth_reduction`）。这导致 Loss 曲面变得像锯齿一样极其粗糙。
    *   **结果**：你在局部算出来的梯度，指向的是乱七八糟的方向，或者是 0。PGD 这种依靠近似梯度的方法就会迷路，找不出攻击样本。
    *   **这就好比**：真正的漏洞在 100 米外，但你在脚下放了无数个小绊脚石。以前的攻击者是看一眼望远镜（算梯度）走过去，现在他光顾着看脚下，以为没路了。

*   **随机化 (Stochastic Gradients)**：
    有些防御在推理时加随机噪声（Random Noise）。每次算出来的梯度都不一样，攻击者很难找到一个稳定的方向。

#### 3. 为什么说是“假安全”？
虽然 PGD（依赖梯度的白盒攻击）算不出梯度失效了，但**漏洞依然存在**。
*   **破解方法**：
    1.  **黑盒攻击**：我不看你的梯度了，我用另一个相似的模型生成攻击样本直接扔给你。因为你没真防御，你的弱点和替身模型是一样的，一打一个准。
    2.  **BPDA (Backward Pass Differentiable Approximation)**：你前向传播不是有 jpeg 压缩这种不可导层吗？我反向传播算梯度时，假装那一层是恒等映射（Identity），直接跳过它算梯度。往往这样一算，又能把你干掉。

---

### 三、 梯度消失 (Gradient Vanishing)

这其实属于梯度掩盖的一种极端情况，但在对抗防御语境下有特定的含义。

#### 1. 现象
梯度不仅是乱的，而是直接变成 **0** 了。

#### 2. 典型案例：饱和激活函数
*   还记得 **FGSM Adversarial Training** 吗？
    Madry 论文里提到，如果你只用 FGSM 这种单步攻击做训练，模型学会了一种“作弊”方式：它会调整权重，让正确分类的 Logits 值变得超级大，或者让 Softmax 进入饱和区。
*   **结果**：
    在 $x$ 附近的局部区域，Loss 函数变得像**平原**一样平（$\nabla_x L \approx 0$）。
    PGD 算出来的梯度是 0，它以为自己已经在极值点了，就不动了。
    **但是！** 只要跨过这个极小的平原，立马就是一个巨大的悬崖（真正的对抗样本）。
    PGD 因为第一步没迈出去，所以没发现悬崖。

---

### 四、 如何检测（照妖镜）？

回到 Madry 的 **Section 5**，这就是为什么他要做那些 Sanity Checks。如果你想检测一个防御模型是不是在搞“梯度掩盖”，看这三条：

1.  **白盒打不过黑盒**：
    *   正常情况：我看你底牌（白盒）应该比瞎猜（黑盒）打得更狠。
    *   梯度掩盖：我看你底牌反而没法打（梯度是坏的），瞎猜反而能打中。**如果你发现 Black-box Accuracy < White-box Accuracy，那这就是梯度掩盖的铁证。**

2.  **一阶攻击打不过零阶攻击**：
    *   如果你发现 PGD（用梯度的）攻击成功率很低，但是用 SPSA 或进化算法（不用梯度的）攻击成功率很高，说明梯度坏了。

3.  **增加扰动大小，攻击效果不提升**：
    *   正常来说，允许的 $\epsilon$ 越大，攻击应该越容易。如果你发现 $\epsilon$ 变大，白盒攻击成功率居然没变，说明梯度被截断或掩盖了。

### 总结

*   **真防御 (Robustness)**：把坑填平了。
*   **梯度掩盖 (Masking)**：把去坑边的路标拔了，或者在路上撒了烟雾弹。

Madry 的 PGD 论文之所以经典，就是因为它**不搞虚的**，通过强大的 PGD 训练（Inner Max），强迫模型真的去填坑，而不是掩耳盗铃。