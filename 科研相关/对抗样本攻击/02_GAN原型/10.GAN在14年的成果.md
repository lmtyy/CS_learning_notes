第五部分 (Experiments) 展示了 GAN 在 2014 年那个时间点的实际表现。

作为大二学生，看这一部分时，我们要带着 **“批判性”且“历史性”的眼光**。因为按照现在的标准（比如 Stable Diffusion 或 StyleGAN），这里的效果简直惨不忍睹。但你必须理解，这可是“开天辟地”的第一刀。

我对这一部分为你做两个层面的解读：

---

### 1. 实验结果：图很糊，但意义重大 (Figures 2 & 3)

请直接看论文最后几页的插图。

#### **Figure 2: 生成样本展示**
*   **最左列 (a) MNIST**：手写数字。生成的数字挺清楚，但这属于“简单任务”。（当时已经是深度学习的 Hello World 了）。
*   **中间 (b) TFD (Toronto Face Database)**：人脸。这些脸看起来有点阴森恐怖，很多都很模糊，五官也不清晰。
*   **右边 (c) CIFAR-10**：常用的小图数据集。你看那个效果，基本上是一团有颜色的浆糊（blurry blob）。

**关键点来了：**
注意看图最右边的一列黄色框住的图。那是 **“Nearest Neighbor”（最近邻）**。
*   **Goodfellow 为什么要放这一列？**
    *   他要证明 G 是真的**学会了画画**，而不是**死记硬背**（Memorization）。
    *   如果 G 生成的图（黄框左边）和训练集里的一张图（黄框内）一模一样，那就说明 G 只是把训练集背下来了，这就是过拟合（Overfitting），没用。
    *   **结论**：你可以看到生成的图和最近邻的图**长得不一样**。这证明 GAN 理解了数据的潜在分布，并且创造出了这一类新的样本。

#### **Figure 3: ==隐空间插值== (Latent Space Interpolation)** (非常重要！)
这是一张展示数字变化的图。
*   **操作**：
    1.  取两个随机噪声 $z_1$ 和 $z_2$。
    2.  $z_1$ 生成了一张图（比如一个 1），$z_2$ 生成了一张图（比如一个 5）。
    3.  在这个噪声空间里做**线性插值**，比如取 $z' = 0.5 z_1 + 0.5 z_2$，然后把 $z'$ 喂给 G。
*   **现象**：你可以看到，当我们在 $z$ 空间移动时，生成的数字是**平滑渐变**的（从 1 慢慢变形变成 5，而不是突然跳变）。
*   **对你的价值**：
    *   这证明了 GAN 学到的特征空间（Latent Space）是**连续的、有意义的**流形（Manifold）。
    *   **对抗攻击的启示**：很多对抗攻击（如基于 GAN 的攻击）就是在这种隐空间里找漏洞。如果你能在这个连续空间里找到一个点，解码出来像熊猫，但分类器认为是长臂猿，你就成功了。

---

### 2. 定量评估：Parzen Window (Table 1)

这里你会看到一张表，比较了 GAN 和其他模型（如 DBN, CAE 等）的 Log-Likelihood（对数似然）。

**我的建议：直接忽略这个表。**

*   **原因**：
    1.  用 Parzen Window 来估算 GAN 的 Likelihood 是非常不准确的（Goodfellow 自己在文中也承认方差很大）。
    2.  后来的研究证明，这种评估指标对 GAN 来说意义不大。现在的 GAN 论文都不用这个了，大家改用 **IS (Inception Score)** 或 **FID (Fréchet Inception Distance)**。
*   **结论**：不要在 Table 1 上浪费时间，它已经在历史长河中被淘汰了。

---

### 总结第五部分

*   **视觉效果**：虽然模糊，但首次证明了对抗训练能让死板的神经网络学会创造。
*   **不过拟合**：证明了不是复制粘贴训练集。
*   **隐空间特性**：证明了学到了平滑的流形结构（这对对抗样本研究至关重要）。

读完这部分，你就读完了整篇论文的主体。剩下的 **Section 6 (Advantages and disadvantages)** 和 **Section 7 (Conclusion)** 其实就是作者对自己工作的总结，你可以把它们当作“太长不看版”的复习材料快速扫过。