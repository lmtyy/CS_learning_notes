**第三部分：非马尔可夫前向过程的变分推导 (Variational Inference for Non-Markovian Forward Processes)**

这一章是整篇论文**最具理论深度**，也是**最“劝退”**的部分。但请不要害怕，对于你要做对抗样本科研来说，你不需要会手推这些公式，你只需要**看懂作者在这个复杂的数学外壳下，玩了一个什么“魔术”**。

这个魔术的核心目的是：**证明 DDIM 可以直接复用 DDPM 训练好的模型。**

我们把它拆解成三个步骤来讲：

---

### 第一步：打破思维定势 —— 谁说必须是马尔可夫链？
**(对应 3.1 节)**

*   **DDPM 的做法**：DDPM 假设加噪过程是一个马尔可夫链（Markov Chain），即 $x_{t-1} \to x_t$ 的分布只依赖于前一步。
    $$q(x_t | x_{t-1}, x_0) = q(x_t | x_{t-1})$$
    这导致采样（去噪）的时候必须严格一步一步倒着走：$x_T \to x_{T-1} \to \dots \to x_0$。

*   **DDIM 的大胆想法**：作者说，我们在训练模型时（如我们在第二部分看到的），Loss 其实只用到了 **边缘分布 $q(x_t|x_0)$**（即直接从 $x_0$ 加噪到 $x_t$ 的那一步）。
    **关键逻辑：** 只要我在每一时刻 $t$，保持 $q(x_t|x_0)$ 这个分布不变（还是那个高斯分布），中间 $x_{t-1}$ 怎么生成的根本不重要！

*   **新的定义 (Non-Markovian)**：
    于是作者构造了一个新的推断分布族 $q_\sigma(x_{1:T}|x_0)$。在这个新定义里，$x_{t-1}$ 不仅取决于 $x_t$，还取决于 $x_0$。
    这就打破了马尔可夫性质，引入了一个新的自由参数 **$\sigma$**。

---

### 第二步：生成过程的重新定义 —— 引入“预测的 $x_0$”
**(对应 3.2 节)**

这是对你理解采样公式（第 4 页）最重要的一步。

在生成（去噪）过程中，既然 $x_{t-1}$ 依赖于 $x_t$ 和 $x_0$，但我们在采样时只有 $x_t$，不知道 $x_0$ 啊？怎么办？

*   **Trick**：用神经网络猜！
*   我们有训练好的神经网络 $\epsilon_\theta(x_t)$，它可以预测噪声。
*   根据公式 $x_t = \sqrt{\alpha_t}x_0 + \sqrt{1-\alpha_t}\epsilon$，我们可以反解出 $x_0$：
    $$
    x_0 \approx \frac{x_t - \sqrt{1-\alpha_t}\epsilon_\theta(x_t)}{\sqrt{\alpha_t}}
    $$
    论文中把这一项称为 **"predicted $x_0$"**（公式 9）。

*   **这一步的意义**：DDIM 采样过程的每一步，实际上都在做一件事：**看着当前的 $x_t$，脑补出最终的 $x_0$ 应该长什么样，然后在这个方向上迈一步走到 $x_{t-1}$。**

---

### 第三步：殊途同归 —— 一个完美的数学巧合
**(对应 3.2 节后半部分 & Theorem 1)**

作者定义了一个全新的变分目标函数 $J_\sigma$。这也是这一章最吓人的数学符号堆砌。

但结论（Theorem 1）非常简单粗暴：
> **Theorem 1**: For all $\sigma > 0$, there exists $\gamma$ and $C$, such that **$J_\sigma = L_\gamma + C$**.

*   **人话翻译**：无论你怎么调整这个参数 $\sigma$（决定过程有多随机或多确定），你会发现最终推导出来的 Loss Function，除了前面系数不一样，和 **DDPM 原来的 Loss Function ($L_\gamma$) 是一模一样的！**

*   **对你的价值**：
    这个定理是这篇论文的“免死金牌”。它保证了：虽然我是这篇论文新提出的 DDIM 方法，但我可以直接拿你在 Github 上找到的所有现成的 DDPM 权重来用。你不需要训练一个 "DDIM 专用模型"。

---

### 第三部分总结：对做对抗攻击的启示

读完这一部分，你应该在脑子里建立起这样一个图像：

1.  **自由度 $\sigma$**：这一章引入了一个神秘参数 $\sigma$。它控制了生成过程的**随机程度**。
    *   当 $\sigma$ 很大时 $\to$ 过程很随机 $\to$ 退化回 **DDPM**。
    *   当 $\sigma = 0$ 时 $\to$ 过程完全确定 $\to$ 变成 **DDIM**。

2.  **攻击的抓手**：
    作为攻击者，你最关心的是系统的**确定性**。
    这一章从数学上向你担保：我们可以合法地将 $\sigma$ 设为 0，从而获得一个**确定性的采样路径**。这个路径上的每一步都在利用神经网络“预测 $x_0$”。

    如果你攻击这个“预测噪声 $\epsilon_\theta(x_t)$”，其实你就是在攻击模型对 $x_0$ 的恢复能力。如果你让模型预测错误的噪声，模型反解出来的 $x_0$ 就会是一张乱码或者你指定的图片。这就是对抗攻击的基本原理。