**第二部分 Background** 是论文的数学地基。它快速回顾了 DDPM（Denoising Diffusion Probabilistic Models）的核心公式。

因为你是大二学生，数学推导可能会让你觉得有点枯燥，但**看不懂这一章，就看不懂 DDIM 后面是怎么魔改公式的**。我会避开繁琐的证明，只带你抓最核心的**三个公式**。这三个公式是整个 Diffusion 领域的“牛顿三定律”。

---

### 1. 正向过程 (Forward Process) —— 把图片变成噪声

> **公式 (3) & (4) 是关键**

在此之前，我们需要定义符号：
*   $x_0$：干净的原图。
*   $x_T$：完全的高斯白噪声。
*   $x_1, \dots, x_{T-1}$：中间带噪图。
*   $\alpha_t$：一个预先定义好的参数，决定了每一步保留多少原图信息。（论文里 $\alpha$ 随着 $t$ 变大而变小）。

**核心公式 (4)：一步到位加噪**
$$
x_t = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t} \epsilon
$$
*   其中 $\epsilon \sim \mathcal{N}(0, I)$ 是随机高斯噪声。
*   **物理意义**：这是一个线性插值。$x_t$ 是“一部分原图”加上“一部分噪声”。$t$ 越大，$\alpha_t$ 越趋近于 0，原图 $x_0$ 的成分就越少，噪声 $\epsilon$ 越多。
*   **价值**：这个公式告诉你，任意时刻的 $x_t$，只要知道 $x_0$，就可以**一步算出**，不需要像马尔可夫链那样一步步迭代。这是训练模型的基础。

---

### 2. 反向过程 (Reverse Process) —— 模型的任务

> **公式 (1) 是关键**

$$
p_\theta(x_{0:T}) := p(x_T) \prod_{t=1}^T p_\theta^{(t)}(x_{t-1}|x_t)
$$

*   **物理意义**：这就是我们想训练的神经网络（生成过程）。
*   它的任务是：给定现在的 $x_t$（带噪图），猜出上一时刻的 $x_{t-1}$（少一点噪的图）。
*   在 DDPM 里，这个 $p_\theta(x_{t-1}|x_t)$ 被假设为高斯分布。神经网络负责预测高斯分布的**均值**。

---

### 3. 训练目标 (Training Objective) —— 怎么教模型

> **公式 (5) 是整章最重要的公式**

$$
L_\gamma(\epsilon_\theta) := \sum_{t=1}^T \gamma_t \mathbb{E}_{x_0, \epsilon} \left[ \| \epsilon_\theta^{(t)}(\sqrt{\alpha_t}x_0 + \sqrt{1-\alpha_t}\epsilon) - \epsilon \|_2^2 \right]
$$

这看起来很吓人，但我们把它剥皮抽筋，看本质：
$$
Loss = \| \text{神经网络预测的噪声} - \text{真实加进去的噪声} \|^2
$$

*   **输入**：给神经网络看一张带噪图 $x_t$（这个 $x_t$ 是通过公式 (4) 用 $\epsilon$ 合成的）。
*   **任务**：问神经网络，“请告诉我，这张图里加的噪声 $\epsilon$ 它是长什么样的？”
*   **输出**：神经网络吐出一个预测噪声 $\epsilon_\theta(x_t)$。
*   **优化**：让预测的噪声和真实的 $\epsilon$ 越像越好（MSE Loss）。

**这里埋下了一个巨大的伏笔：**
作者特别指出，这个 Loss function 只依赖于边缘分布 $q(x_t|x_0)$（即公式 4）。
作者在 Section 3 会利用这一点反过来推导：**既然训练只看这一步，那只要我不改变 $q(x_t|x_0)$，中间的马尔可夫链怎么改（变成非马尔可夫），模型训练都不受影响！**

---

### 第二部分对你科研的实战意义

作为一个要做对抗攻击的人，你在这一章需要 Get 到两点：

1.  **攻击对象是谁？**
    攻击的对象是神经网络 $\epsilon_\theta(x_t)$。你的目标通常是给 $x_t$ 加一个微小的扰动 $\delta$，使得输出 $\epsilon_\theta(x_t + \delta)$ 发生剧烈变化，或者指向错误的方向。

2.  **梯度从哪来？**
    公式 (5) 也是你做 **对抗训练 (Adversarial Training)** 的 Loss 来源。
    如果你想让 Diffusion 模型防御攻击，你需要稍微修改这个 Loss：
    $$
    Loss_{Adv} = \| \epsilon_\theta(x_t + \delta) - \epsilon \|^2
    $$
    其中 $\delta$ 是通过攻击算法算出来的。你需要让模型在看过这类扰动数据后依然能预测出正确的噪声。

读懂这一章，你就知道了 Diffusion 模型的 **输入（带噪图）、输出（预测噪声）和 训练方式（MSE）**，这是你编写 PyTorch 代码的基础。