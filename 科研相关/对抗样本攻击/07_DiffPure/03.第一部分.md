这篇论文的 **Introduction（第1部分）** 写得非常标准且逻辑严密，堪称写顶级会议论文的教科书范本。既然你已经有扎实的基础，我将剥离掉客套话，直接用 **“起承转合”** 的逻辑框架为你拆解这一部分。

Introduction 的核心任务是回答三个问题：**为什么做这个？为什么以前的方法不行？我们是怎么做成的？**

---

### 第一层：现状与痛点 —— “对抗训练”虽强，但太笨重（起）
> *Reference: Paragraph 1*

首先，作者承认了目前的防御霸主是 **Adversarial Training (AT)**（比如 Madry 的 PGD-Training）。
*   **承认优点**：AT 确实有效，是目前的 Standard。
*   **指出软肋**：
    1.  **特化太强**：你用 $L_\infty$ 攻击去训练，它就防不住 $L_2$ 攻击（泛化性差）。
    2.  **性能牺牲**：为了防御，模型在干净数据上的准确率（Clean Accuracy）通常会大幅下降。
    3.  **训练昂贵**：对抗训练非常慢（你知道的，每次迭代都要先生成攻击样本）。

**Key Insight:** 这为作者引入“即插即用”的方法埋下了伏笔——我们需要一种不需要重新训练模型的防御。

---

### 第二层：备选方案 —— “对抗净化”好用，但工具不行（承）
> *Reference: Paragraph 2*

作者转向了另一条路：**对抗净化 (Adversarial Purification)**。
*   **逻辑**：我不改分类器，我只用一个生成模型把输入图片的噪声洗掉。
*   **优点**：**Plug-n-Play（即插即用）**。不管你后面接的是 ResNet 还是 ViT，我都能防。
*   **痛点**：以前大家用 GAN（如 Defense-GAN）或 EBM（Energy-Based Models）做净化，但效果一直打不过 AT。
*   **原因**：**以前的生成模型不够强**。GAN 有 Mode Collapse（模式崩塌），EBM 生成质量差。工具不行，不是净化这个思路不行。

**Key Insight:** 这里点出了机会点——那是生成模型的问题，现在有了更强的 Diffusion Model，净化的翻身仗来了。

---

### 第三层：破局者 —— 为什么 Diffusion Model 是天选之子？（转）
> *Reference: Paragraph 3*

如果你对 DDPM 熟悉，这里你会非常有共鸣。作者论证了 Diffusion 完美契合对抗防御的两个特性：
1.  **强分布建模能力**：Diffusion 生成的图片质量和多样性吊打 GAN，这意味着净化后的图片更接近真实的干净分布（Clean Distribution）。
2.  **天生的净化机制**：
    *   **Forward Process**：把数据变成噪声。这其实是一个“清洗”过程，对抗扰动（微小的结构化噪声）会被高斯噪声淹没。
    *   **Reverse Process**：从噪声变回数据。这是“重建”过程，把内容找回来。
3.  **随机性 (Stochasticity)**：Diffusion 本身是概率性的，这种随机性天然地让攻击者很难计算准确的梯度（Stochastic Defense）。

---

### 第四层：DiffPure 的核心逻辑 —— 先破坏，再重建（合）
> *Reference: Paragraph 4 & 5*

这里作者正式抛出了 **DiffPure** 的工作流程（对应论文图1）：
1.  **操作**：拿到一张对抗攻击图 $x_{adv}$，不要直接去修。
2.  **Diffuse**：先沿着 Forward SDE 加一点噪，走到时刻 $t^*$。这时，对抗扰动被破坏了。
3.  **Recover**：再沿着 Reverse SDE 走回来，还原出 $x_{clean}$。
4.  **Trade-off**：作者在这里提到了一个关键点——$t^*$ 是个超参数。
    *   **加噪太少 ($t^*$小)**：扰动没洗干净。
    *   **加噪太多 ($t^*$大)**：图的语义变了（比如猫变成了狗），分类器也会错。
    *   **结论**：需要找到一个 **Sweet Spot（最佳平衡点）**。

**(进阶) 技术护城河：Adjoint Method**
在这一段，作者特意强调了 **Evaluate against strong adaptive attacks**（在强自适应攻击下评估）。
*   为了证明自己不是在搞“梯度掩盖”这种虚假的防御，作者必须让攻击者能算出整个 SDE 的梯度。
*   为了解决显存爆炸问题，他们引入了 **Adjoint Method**。这是这篇论文技术含金量最高的地方，把一个工程问题转化为了数学问题解决。

---

### 第五层：总结贡献 —— 我们赢了
> *Reference Paragraph 6 (Contribution)*

作者列举了四大贡献（这也是你后续复现要关注的点）：
1.  提出了 **DiffPure**：第一个利用正向/反向扩散过程做净化的。
2.  **理论分析**：证明了 Forward 过程确实能消除对抗扰动（对应后面 Section 3.1 的定理）。
3.  **Adjoint Method**：解决了 SDE 梯度计算的内存瓶颈，使得评估变得可行。
4.  **SOTA 结果**：在 CIFAR-10, ImageNet, CelebA-HQ 上大幅超越现有的 AT 和净化方法。

---

### 对你后续复现的指导意义

读完 Introduction，你应该在脑子里建立起这样的复现蓝图：

1.  **你需要两个模型**：一个用来分类（比如预训练好的 WideResNet），一个用来净化（预训练好的 DDPM/Score SDE）。**不要自己训练 Diffusion！** Intro 里说了利用预训练模型是优势。
2.  **核心复现代码**：就在于那个 **Diffuse -> Recover** 的过程。
3.  **关键参数**：Introduction 明确说了 $t^*$ 很重要。你在做实验时，一定要调节 $t^*$（比如 0.1, 0.2, 0.3...），观察防御效果的变化，这能直接对应上作者说的 Trade-off。
4.  **不用一开始就碰 Adjoint Method**：如果你只是先跑通净化流程（Inference），不需要 Adjoint Method。只有当你想要对你的复现结果进行**白盒攻击（BPDA+EOT）**来测试它到底有多硬时，才需要去啃 `torchsde` 库里的 Adjoint 功能。

接下来，建议直接阅读 **Section 3 (Method)**，那里会把 Intro 里说的 "Diffuse -> Recover" 变成具体的数学公式。