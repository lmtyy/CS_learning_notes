**第四部分 (Section IV. Experimental Setup)** 是论文中最容易被忽视，但对于复现和理解实验严谨性至关重要的一节。

如果是做粗略阅读，这部分通常扫一眼即可。但因为你是相关方向的科研新手，我建议留心作者是如何**搭建实验环境**的。这种标准化的设定（Setup）是后续所有对比实验公平性的基石。

这部分内容比较简短，主要交代了两个核心要素：**模型（Models）** 和 **数据集（Datasets）**。

---

### 1. 数据集 (Datasets)

作者选择了当时最具代表性的三个计算机视觉数据集，分别代表了三种不同的难度层级：

*   **MNIST:**
    *   **任务：** 手写数字识别（0-9，灰度图）。
    *   **难度：** **简单（Toy Example）**。
    *   **地位：** 当时的 Hello World。在这个数据集上做到 99% 的准确率很容易，如果攻击连这个都搞不定，那就没戏了。
*   **CIFAR-10:**
    *   **任务：** 10类物体分类（飞机、汽车、鸟等，彩色图 32x32）。
    *   **难度：** **中等**。
    *   **地位：** 比 MNIST 复杂得多，更能模拟真实世界的图像特征。作者在这里重现了 defensive distillation 的原始实验。
*   **ImageNet (Inception v3):**
    *   **任务：** 1000类物体分类（高分辨率，299x299）。
    *   **难度：** **困难（Real World）**。
    *   **地位：** 这是工业级的标准。之前的攻击算法（如 JSMA）在这个量级上往往因为计算量太大而跑不动。C&W 能在这里跑通，证明了其算法的可扩展性。

---

### 2. 模型架构与训练 (Model Architectures)

这里作者有一个非常重要的科研态度：**完全复刻（Reproducibility）**。

*   **MNIST & CIFAR-10 模型:**
    *   作者**并没有**使用当时最 SOTA（State-of-the-Art）的模型架构。
    *   **原因：** 因为他们的打击目标是 **Defensive Distillation (Papernot et al., 2016)**。为了公平起见，作者**一模一样地**复制了 Papernot 论文中的网络结构（卷积层数量、参数、ReLU等）和超参数（学习率、动量等）。
    *   **目的：** 这样做是为了防止扯皮。如果作者用了不同的模型攻破了防御，Papernot 可能会说“那是你模型结构的问题，不是我防御方法的问题”。哪怕完全一样，攻击成功率也达到了 100%，这就是实锤。
    *   *注：他们在 CIFAR-10 上的模型其实有点过拟合（训练集98%，验证集80%），但为了保持一致性，他们没有做额外的数据增强。*

*   **ImageNet 模型:**
    *   作者直接使用了预训练好的 **Inception v3**。
    *   这是一个非常深、非常复杂的网络。能攻破它，说明 C&W 攻击对深层特征的理解和利用是非常到位的。

---

### 3. 这部分对你的启示

1.  **控制变量法：** 当你想证明你的攻击比别人强，或者你的防御比别人好时，**必须**保证其他条件（模型结构、训练参数）和对比对象完全一致。
2.  **难度分级：** 在未来的论文里（比如做 GAN/Diffusion 生成对抗样本），只做 MNIST 是不够的，甚至只做 CIFAR 也是不够的。现在的审稿人通常要求必须在 ImageNet 或 CelebA-HQ 这种高分辨率数据集上验证你的方法。C&W 在 2017 年就确立了这个多级验证的标准。

读完这一节，我们就知道舞台已经搭好了：**完全复刻的靶子模型**已就位，接下来就是 **Section V (Our Approach)** 中新式武器的登场了。