第四部分 (Theoretical Results) 充满了数学证明（主要涉及概率密度函数、Kullback-Leibler 散度和 Jensen-Shannon 散度）。

**针对你的情况（大二、对抗样本攻击方向、刚入门）：**
这一部分属于“**如果你想发顶级理论文章必须会，但如果你只要做实验和搞攻击算法，知道结论就行**”的范畴。

在 FGSM 领域，你其实也不太纠结“为什么梯度攻击一定能收敛”，而是更关心“它能不能骗过模型”。同样，对于 GAN，建议你**不要深究证明过程**，而是掌握以下**三个核心理论结论**。这些结论是你理解这里发生了什么的定心丸。

---

### 结论 1：判别器 D 的最优解是什么？ (Proposition 1)

**问题**：如果此时此刻，我不动 G（生成器固定好了），只让你训练 D，把它训练到极致，D 最终会变成什么样子？

**答案**：
最优的判别器 $D^*(x)$ 满足以下公式：
$$ D^*_G(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)} $$

*   $p_{data}(x)$：这是真实数据在 $x$ 这一点的概率密度（比如这里是一张真熊猫图的可能性）。
*   $p_g(x)$：这是生成数据在 $x$ 这一点的概率密度（比如 G 生成一张像熊猫的图的可能性）。

**直观理解**：
*   **如果 $x$ 看起来像真图**（$p_{data}$ 很大，$p_g$ 很小）：$D^*(x) \approx \frac{\text{大}}{\text{大} + \text{小}} \approx 1$。D 会判定为真。
*   **如果 $x$ 看起来像假图**（$p_{data}$ 很小，$p_g$ 很大）：$D^*(x) \approx \frac{\text{小}}{\text{小} + \text{大}} \approx 0$。D 会判定为假。
*   **如果 G 很完美了**（$p_{data} = p_g$）：也就是这张图既像真的，也像假的，两个概率相等。$D^*(x) = \frac{p}{p+p} = 0.5$。这就是瞎猜的状态。

**对你的价值**：
这个公式告诉你，D 的判断依据本质上是**两个概率分布的比值**。对抗攻击其实就是在利用这个分类边界。

---

### 结论 2：这就叫 JS 散度 (Equation 5 & 6)

**问题**：当我们把最优的 D 代入回去，G 到底在最小化什么东西？

**答案**：
这一段证明了，训练 GAN 本质上是在**最小化真实分布 $p_{data}$ 和生成分布 $p_g$ 之间的 Jensen-Shannon (JS) 散度**。

$$ C(G) = -\log(4) + 2 \cdot JSD(p_{data} \| p_g) $$

*   **JS 散度**是一个衡量两个概率分布距离的指标。如果两个分布一模一样，JS 散度为 0。
*   **Goodfellow 的潜台词**：你看，我不直接算概率距离（因为算不动），但我设计了这个 Min-Max 游戏，玩到最后，竟然**等价于**我在最小化 JS 散度！这就证明了我的算法在数学上是合理的。

---

### 结论 3：最后的唯一解 (Theorem 1)

**问题**：这个游戏玩到最后，一定会有一个结局吗？

**答案**：
是的。在无限制的模型能力（Non-parametric limit）下，GAN 只有**唯一**的一个全局最优解：
$$ p_g = p_{data} $$
即：生成器分布完全重合于真实数据分布。

此时，$D(x)$ 对所有输入都输出 $\frac{1}{2}$。博弈结束，不再有梯度产生（警察和造假者都失业了，因为假币已经真假难辨）。

---

### 用一句话总结第四部分

Goodfellow 用数学证明了：**玩这个警察抓小偷的游戏，只要大家都能学到极致，最终结果一定是小偷完美复制了真币（$p_g=p_{data}$），而这就是我们训练生成模型梦寐以求的结果。**

---

### 你的阅读策略

*   **证明过程**：可以**完全跳过**（涉及到的 KL/JS 散度推导，等你以后如果需要从数学角度改进 GAN 的稳定性，也就是读 Wasserstein GAN 这篇论文时再补也不迟）。
*   **记住结论**：知道 GAN 实际上是在拉近两个分布的距离，这就足够你了。

你可以直接跳到 Section 5 (Experiments) 看图了！