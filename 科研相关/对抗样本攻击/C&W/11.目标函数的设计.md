好的，我们把镜头推近，详细拆解一下 **第五章第一步：目标函数的设计 (Objective Function Design)**。

做科研要有“侦探思维”，我们不仅要看作者最后选了什么，更要看他**尝试了什么**以及**为什么别的即使看起来很合理但却失败了**。这通过对比，你对 Loss Function 的理解会深刻很多。

---

### 1. 问题的定义

我们的总目标是解决这个优化问题：
$$ \text{minimize } ||\delta||_p + c \cdot f(x+\delta) $$
如果不满足 $f(x+\delta) \le 0$，攻击就判定失败（即分类没变）。

作者通过实验测试了 **7种** 可能的函数 $f$。这 7 种函数其实代表了深度学习中常见的几种 Loss 设计思路。

假设：
*   $t$ 是我们想攻击的目标类别（Target Class）。
*   $Z(x)$ 是 Logits（Softmax 之前的原始得分），$Z(x)_i$ 是第 $i$ 类的得分。
*   $F(x)$ 是 Softmax 后的概率，$F(x)_i$ 是第 $i$ 类的概率。

---

### 2. 七种候选函数大比拼 (Which one is the best?)

这里我挑几个最有代表性的来讲，它们展示了不同的思维陷阱。

#### ❌ **$f_1$ (Cross Entropy Loss)**
$$ f_1(x') = -\text{loss}_{F, t}(x') + 1 $$
*   **思路：** 这是最自然的。我们训练网络不就是为了让 Cross Entropy 变小吗？那我就直接把 Cross Entropy 怼进去。
*   **为什么失败？**
    *   **梯度饱和/消失：** Cross Entropy 是基于 Softmax 概率算的。对于 Defensive Distillation（防御蒸馏）的模型，它会让非目标类别的概率变得极小（比如 $10^{-30}$）。
    *   在计算机浮点数里，这么小的数可能直接就变成 0 了，或者梯度极其微小。
    *   结果：优化器一看梯度是 0，以为已经到终点了，就不动了。实际上根本没攻进去。

#### ❌ **$f_3$ (Softmax Probabilities)**
$$ f_3(x') = \max_{i \neq t} F(x')_i - F(x')_t $$
*   **思路：** 只要“目标类别的概率”比“最大非目标类别的概率”大，这数就是负的，攻击就成功了。听起来很合理。
*   **为什么失败？**
    *   还是**梯度消失**的问题。因为 $F(\cdot)$ 是 Softmax 后的结果。Softmax 函数在两端（极值处）是十分平缓的。
    *   当 Logits 差距很大时（比如一个 100，一个 50），经过 Softmax 后一个是 1.0，一个是 0.0。这时候不管怎么求导，导数都接近 0。优化器又推不动了。

#### ✅ **$f_6$ (Logit Margin Loss)** —— 最后的赢家
$$ f_6(x') = \max(\max_{i \neq t} Z(x')_i - Z(x')_t, -\kappa) $$
*   **思路：** 不要看概率 $F$，直接看原始得分 $Z$。只要“目标得分 $Z_t$” 比 “第二名的得分 $Z_{max(i \neq t)}$” 大，攻击就算成功。
*   **为什么成功？**
    *   **线性特性：** Logits 通常是无界的，而且不像 Softmax 那样容易饱和。即便 $Z_t$ 已经是 100 了，$Z_{other}$ 是 50，梯度依然很大（想要把它拉得更开或更近）。
    *   **鲁棒性：** 它完全绕过了 Softmax 造成的梯度屏蔽问题。

---

### 3. $f_6$ 的深度解析（必考点）

我们再细看一下这个公式：
$$ \max( \underbrace{\max_{i \neq t} Z(x')_i - Z(x')_t}_{\text{Margin项}}, \quad \underbrace{-\kappa}_{\text{截断项}} ) $$

#### **A. Margin 项的物理意义**
假设要让图变成“猫” ($t=$猫)。
*   如果不含猫的类别里，得分最高的是“狗” ($Z_{dog}=10$)。
*   猫目前的得分是 $Z_{cat} = 8$。
*   Margin = $10 - 8 = 2$。正数 -> 说明还要努力，梯度会推着让猫的分变高，狗的分变低。
*   如果优化后，猫得分变成 12。
*   Margin = $10 - 12 = -2$。负数 -> 攻击成功！

#### **B. $-\kappa$ (Kappa) 的作用**
这叫 **Confidence Bound（置信度边界）**。
*   如果 $\kappa = 0$: Margin 只要变成负数（猫比狗大 0.00001 分），Loss 就取 0 了（$\max(-2, 0) = 0$）。优化停止。
    *   **结果：** 攻击刚好成功，但很勉强。可能加上一点随机噪声，又变回狗了。
*   如果 $\kappa = 10$: 意味着 Margin 必须达到 -10 才能停止。也就是 $Z_{cat}$ 必须比 $Z_{dog}$ 大 10 分。
    *   **结果：** 攻击非常稳（High Confidence）。这就是作者在摘要里说的“High-confidence adversarial examples”。这对于衡量**迁移性**非常重要——信心越足的攻击样本，越容易迁移到别的黑盒模型上去。

---

### 4. 总结：第一步的核心逻辑

作者通过对比告诉我们：
在做对抗攻击（或者任何涉及神经网络输出控制的任务）时，**千万不要直接优化 Softmax 后的概率或 Cross-Entropy Loss**，因为那里全是梯度陷阱。

**直接优化 Logits 的差值（Margin）** 是最稳健、最有效的方法。这个经验至今仍是 AI 安全领域的黄金法则。