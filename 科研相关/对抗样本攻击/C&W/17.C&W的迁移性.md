迁移性（Transferability）确实是对抗攻击里一个非常神奇也很重要的概念。

这里有三个核心点需要理清：**什么是迁移性**、**为什么 C&W 本来迁移性不好**、**为什么加了 $\kappa$ 就变好了**。

---

### 1. 什么是迁移性 (Transferability)？

迁移性是指：**我在模型 A 上生成的对抗样本，直接拿去攻击模型 B，居然也能成功！**

*   **模型 A (Source Model):** 白盒模型，你手里有它的所有参数。
*   **模型 B (Target Model):** 黑盒模型，你看不到它的参数，甚至结构可能都不一样（比如 A 是 ResNet，B 是 VGG）。

这在现实中非常可怕。比如我想攻击特斯拉的自动驾驶，但我拿不到它的源代码。我可以自己在家里训练一个类似的模型 A，在 A 上生成攻击图片，然后贴到特斯拉摄像头前（模型 B），如果迁移性好，特斯拉就会撞车。

---

### 2. 为什么通常 C&W 迁移性不如 FGSM？

这涉及到**“过拟合 (Overfitting)”**的概念。

*   **FGSM (一波流):**
    *   FGSM 只走一步梯度。它攻击的是模型梯度的**大方向**。
    *   因为深度学习模型即使结构不同，对于同样的图片，它们提取的特征大方向往往是一致的（比如都认为这一块是猫耳朵）。
    *   所以 FGSM 这种粗糙的攻击，反而更容易迁移。

*   **C&W (精雕细琢):**
    *   C&W 是针对模型 A 的决策边界进行**极度精细的优化**。
    *   它就像是一个做微雕的工匠，它可以找到模型 A 决策边界上一个极小的漏洞，只要把像素稍微改一点点（$||\delta||$ 极小），就能刚好跨过那条线。
    *   **问题是：** 模型 B 的决策边界虽然在大体上和 A 差不多，但在细节上肯定不一样。
    *   C&W 针对 A 找到的那个微小的漏洞，在 B 除了可能根本不是漏洞。
    *   **结论：** C&W 为了追求最小扰动，在这个特定模型上**过拟合**了。

---

### 3. 为什么加了 $\kappa$ (Kappa) 迁移性就变好了？

还记得我们之前那个“跑步比赛”的比喻吗？ $\kappa$ 是要求必须甩开对手一段距离。

*   **没有 $\kappa$ ($\kappa=0$):**
    *   C&W 刚好把样本推过模型 A 的边界线 1 毫米。
    *   模型 B 的边界线可能稍微偏了 1 厘米。
    *   结果：样本在 A 上是猫，在 B 上依然是狗。**迁移失败。**

*   **有高 $\kappa$ ($\kappa=20$):**
    *   C&W 被强迫把样本推过模型 A 的边界线 **10 米远**。也就是让 $Z_{target}$ 远大于 $Z_{other}$。
    *   这意味着攻击后的图片具有极强的“猫”特征（对于神经网络而言）。
    *   这时候，哪怕模型 B 的边界线偏了 1 厘米、甚至偏了 5 米，这个样本依然落在模型 B 的“猫”区域内。
    *   **结果：** **迁移成功！**

### 总结

*   **普通的 C&W:** 追求极致的小扰动 -> 刚好跨过边界 -> 容易针对特定模型过拟合 -> **迁移性差**。
*   **高 $\kappa$ 的 C&W:** 放弃极致的小扰动（允许扰动稍微大一点） -> 强力推过边界深处 -> 特征极其显著 -> **迁移性强**。

这就好比：
普通的 C&W 是做弊，只把答案写在只有监考老师 A 能看见的死角，换个老师 B 就露馅了。
高 $\kappa$ 的 C&W 是直接把卷子改得无可挑剔，不管哪个老师来改卷，都得给满分。