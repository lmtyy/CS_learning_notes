我们现在来到 **论文的第三部分（Section III. Attack Algorithms）**。

这一章相当于一次**“战前阅兵”**。在作者亮出自己的“大杀器”（C&W 攻击）之前，先系统地把当时（2016-2017年）市面上已有的主流攻击算法拿出来点评了一番。

阅读这部分的主要目的是：**了解前人的局限性，从而理解为什么需要 C&W 攻击。**

作者把之前的攻击分为了三类（对应上一节定义的三种距离度量），我们逐一来看：

---

### 1. L-BFGS (Optimized for $L_2$)
这是 Szegedy 等人最早发现对抗样本时提出的方法（2013年）。

*   **原理：**
    它试图直接解一个带约束的优化问题：
    $$ \text{minimize } c \cdot ||x - x'||_2^2 + \text{loss}_{F, l}(x') $$
    通过 L-BFGS（一种二阶优化算法）来求解。
*   **作者的评价（缺点）：**
    *   **太复杂、太慢：** 这个优化问题是非线性的，而且使用了当时的 Box-constrained L-BFGS 求解器，很难调参。
    *   **效果一般：** 它是为了证明“对抗样本存在”而设计的，并没有追求“最小扰动”，所以找到的噪声往往不是最优的。
    *   **关键铺垫：** 你会发现 C&W 攻击的数学形式和这个很像（都有 regularization term + loss term），但 C&W 改进了 Loss 函数和求解策略（改用 Adam），把这个思路发挥到了极致。

---

### 2. Fast Gradient Sign Method (FGSM) 已演化为 Iterative Gradient Sign
这部分你应该很熟悉了，就是 Goodfellow 提出的。

*   **原理：**
    $$ x' = x - \epsilon \cdot \text{sign}(\nabla \text{loss}(x)) $$
    这是一步攻击。后来 Kurakin 提出了 **Iterative Gradient Sign (即现在的 I-FGSM 或 PGD 的雏形)**，就是把这一步拆成多步走，每一步走一点点（$\alpha$），最后截断（Clip）。
*   **作者的评价（缺点）：**
    *   **定位不同：** FGSM 设计初衷是**“快”**（Fast），而不是**“强”**（Optimal）。它是为了快速生成大量样本去训练模型，而不是为了找到最小的那个扰动。
    *   **精度不够：** 即使是迭代版本（I-FGSM），也是在超立方体（$\epsilon$-ball）边缘游走，很难精确找到那个使得攻击成功且距离原图最近的点。

---

### 3. JSMA (Optimized for $L_0$)
这是 Papernot（也就是防御蒸馏提出者）提出的攻击，专门针对 $L_0$ 范数。

*   **原理：**
    *   JSMA 不会像 FGSM 那样动所有像素，而是**贪心（Greedy）**地、一个一个地选像素去修改。
    *   它计算一个“显著性图（Saliency Map）”，找出哪两个像素对目标分类影响最大，然后把这两个像素推满（改到0或1）。重复这个过程直到攻击成功。
*   **作者的评价（缺点）：**
    *   **计算极其昂贵：** 因为要计算所有像素对之间的关系，如果你是一张大图（比如 ImageNet 299x299），JSMA 根本跑不动（无法在合理时间内算出结果）。
    *   **局限性：** 这种贪心策略不一定能找到全局最优解。而且正如作者后面指出的，C&W 提出的 $L_0$ 攻击比 JSMA 更有效且更快。

---

### 4. DeepFool (Optimized for $L_2$)
这也是一个很经典的攻击。

*   **原理：**
    *   它假设神经网络分界面是线性的（虽然不是，但局部近似它是）。
    *   然后算一下当前点距离这个线性边界有多远，直接把点推过边界。迭代几次直到真的跨过非线性边界。
*   **作者的评价（缺点）：**
    *   DeepFool 是**非目标攻击（Untargeted）**：它只想让你出错，不管错成啥样。而 C&W 关注的是难度更高的**目标攻击（Targeted）**（我指定要把你识别成鸵鸟）。
    *   虽然 DeepFool 效果不错，但在面对防御机制（如蒸馏）时，因为它依赖梯度指向边界，一旦梯度消失，DeepFool 也会失效。

---

### 总结 Section III：为什么要写这一章？

作者写这一章不仅仅是为了做 Literature Review，更是为了给后面的实验埋下伏笔。

这章传达了一个核心信息：
**现有的攻击各有各的毛病。**
*   L-BFGS 太老太笨重。
*   FGSM/I-FGSM 只求快不求精。
*   JSMA 算不动大图。
*   DeepFool 不支持指定目标。
*   **最重要的是：这些攻击都依赖原始的 Cross-Entropy Loss 或 Softmax 梯度，这正是无论它们怎么努力，都攻不破防御蒸馏的根本原因。**

这就自然引出了下一章（Section IV & V）：我们需要一个**基于 Logits、专门设计 Loss、且支持所有距离度量**的全新优化攻击——即 C&W。