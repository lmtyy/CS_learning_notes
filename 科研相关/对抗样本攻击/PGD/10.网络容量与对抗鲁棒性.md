**Section 4: Network Capacity and Adversarial Robustness (网络容量与对抗鲁棒性)**

如果说 Section 2 和 3 分别解决了“数学理论”和“优化方法”的问题，那么 Section 4 就回答了一个非常实际的工程问题：
**“如果要训练一个防得住 PGD 的模型，我的神经网络需要长什么样？”**

这一节的核心洞见只有两个字：**容量 (Capacity)**。

---

### 一、 核心观点：鲁棒分类比普通分类更难

作者在一开始就抛出了一个非常反直觉（或者说是反传统认知）的观点：
**想要获得对抗鲁棒性，我们需要比以前大得多的网络。**

为什么？请看那个经典的 **Figure 3（决策边界示意图，Decision Boundary）**。

#### 1. 普通分类任务 (Standard Task)
*   **任务**：只需要把数据点（蓝点和红点）分开。
*   **边界**：只需要一条很简单的线（甚至直线）就能把它们切开。
*   **网络需求**：小网络（Small Capacity）就够了。

#### 2. 鲁棒分类任务 (Robust Task)
*   **任务**：不仅要把点分开，还要把每个点周围的 **$\epsilon$-ball（$l_\infty$ 球）** 全部切开。你要保证蓝点的球里全是“蓝区”，红点的球里全是“红区”。
*   **边界**：为了绕开所有的 $\epsilon$-ball，这条决策边界必须扭来扭去，变得非常复杂、曲折。
*   **网络需求**：只有非常深、非常宽的大网络（Large Capacity），其非线性拟合能力才足以画出这么复杂的边界。

---

### 二、 实验验证：从小到大

Madry 团队为了验证这个理论，做了非常扎实的控制变量实验（Figure 4）。

#### 1. 实验设置
他们不仅测试了 MNIST（简单的卷积网），还测试了 CIFAR10（ResNet）。
重点在于，他们通过 **成倍增加卷积核的数量（Width Multiplier）** 来控制网络的“容量”。
*   比如 "Capacity scale 1" 是基础版。
*   "Capacity scale 10" 是把每一层变宽10倍的超大版。

#### 2. 三个关键实验现象

*   **现象一：容量本身就有帮助 (Capacity alone helps)**
    即使不做对抗训练（只做 Natural Training），只要网络变大了，它天然地就会比小网络稍微鲁棒一点点（这里的鲁棒是指针对弱攻击或者小 $\epsilon$）。这说明大网络确实能拟合出更复杂的边界。

*   **现象二：小网络会遭遇“灾难性过拟合” (Small networks fail)**
    **这是最精彩的发现**。
    如果你强行用强大的 PGD 攻击去训练一个小网络，结果会怎样？
    *   **预期**：鲁棒性稍微变好一点？
    *   **实际**：模型直接崩溃了（准确率掉到 0% 或者乱猜）。
    *   **原因**：因为任务太难了（要绕开那么多球），小网络的脑容量不够用，既然学不会怎么绕开球，它干脆摆烂，放弃治疗。**这证明了对抗训练对模型容量有一个“门槛”要求。**

*   **现象三：越大的网络，对抗训练效果越好**
    当网络容量超过那个门槛后，随着网络变大，对抗训练后的 Adversarial Accuracy 会稳步上升。在 CIFAR10 上，他们必须用非常宽的 ResNet 才能达到几十个百分点的鲁棒性。

---

### 三、 所谓的“标签泄漏” (Label Leaking) 的辟谣

在这一节，作者还顺带解决了一个学术界的争论——关于 **FGSM Adversarial Training** 为什么无效。

*   **FGSM Training 的假象**：以前大家发现，用 FGSM 样本加入训练，模型对 FGSM 的防御率变得很高（比如 90%）。
*   **真相**：但这并不代表模型变强了。作者指出，这是模型 **“过拟合”** 了 FGSM 生成的那极其特定的攻击模式。这种现象被称为 **Label Leaking（标签泄漏）**。
*   **只要换成 PGD 攻击**：那个 FGSM 训练出来的模型的准确率瞬间掉回 0%。
*   **结论**：只有足够大的容量 + PGD 这样足够强的攻击，才能真正提升鲁棒性，而不是在那儿自欺欺人。

---

### 🚀 总结 Section 4 对你科研的指导

这一节对你以后做实验是**最直接的避坑指南**：

1.  **别用太小的模型**：如果你想复现 Madry 的结果，或者做新的对抗防御研究，千万别为了省显存去用那种 LeNet 或者很窄的 ResNet-18。如果网络太小，你死活训练不出来，不是你的代码写错了，是模型的脑子（Capacity）不够用。
    *   *建议起手：WideResNet-34-10 (WRN-34-10) 是对抗防御领域的标配基准模型。*

2.  **理解 Trade-off (权衡)**：这节暗示了一个代价。为了换取安全性（Robustness），我们不得不付出巨大的计算代价（更大的模型、训练更慢）。这也是目前该领域的一个研究热点：**“如何用小一点的模型实现同样的鲁棒性？”**（比如模型剪枝、蒸馏在鲁棒性上的应用）。