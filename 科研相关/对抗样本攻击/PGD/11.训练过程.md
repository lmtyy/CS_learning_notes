第五部分（Section 5）是这篇论文的**“大结局”**：它是之前所有理论（Saddle Point）、假设（Universal Adversary）、和洞见（Capacity）的集大成者。

作者在这里展示了基于上述原则训练出的模型的**实际战果**。虽然篇幅较长，但我们可以将其清晰地拆解为**“训练过程”**和**“评估结果”**两部分来看。

我们先来讲前半部分：**怎么训练出来的？（The Recipe & Training Process）**。

---

### 一、 核心训练配方 (The Training Recipe)

基于之前的章节，作者给出了一个在 MNIST 和 CIFAR10 上训练鲁棒模型的标准流程。这个流程后来成为了全行业的 **"Madry's PGD Training" 标准范式**。

#### 1. 核心要素
*   **网络架构**：必须够大（呼应 Section 4）。
    *   **MNIST**：用了一个相当大的 CNN（两层卷积 + 两个全连接）。
    *   **CIFAR10**：用了 **Wide ResNet (WRN)**。这是关键——他们把普通 ResNet 的通道数扩大了 10 倍。
*   **攻击手段（Inner Loop）**：必须是 PGD（呼应 Section 3）。
    *   **MNIST**：PGD 40 步。
    *   **CIFAR10**：PGD 7 步。（为什么只有 7 步？为了省时间，而且实验发现 7 步生成的样本已经足够有代表性了）。

#### 2. 训练动态：看 Loss 曲线 (Figure 5)
作者展示了训练过程中 Loss 的变化图（Figure 5），这非常重要，因为它验证了 Min-Max 优化是真正起作用的。

*   **观察**：这就是那条红色的线——**Adversarial Loss**。
*   **现象**：随着训练进行（Epoch 增加），对于每一个 Batch 生成的**对抗样本的 Loss** 都在稳步下降。
*   **意义**：
    *   这说明 `optimizer.step()`（Min 这一步）确实能压制住 `attacker.step()`（Max 这一步）。
    *   如果训练失败（比如模型容量太小），你会看到这条线根本降不下去，或者震荡。
    *   这个图向大家证明：**那个看起来很难解的 Min-Max 问题，实际上是可以被 SGD 驯服的。**

---

### 二、 主要战果：白盒防御能力 (White-box Robustness)

这是 Section 5 最硬核的数据，也是这篇论文让当时整个学术界震惊的原因。

请看 **Table 1 (MNIST)** 和 **Table 2 (CIFAR10)**。

#### 1. MNIST 的结果
*   **背景**：MNIST 以前大家都觉得容易防，但实际上很多防御方法一遇到强力攻击就崩了。
*   **Adversarial Accuracy**：Madry 的模型在面对最强的 PGD 攻击（甚至跑 100 步）时，准确率依然高达 **89% 以上**。
*   **结论**：在 MNIST 这种简单的黑白数字数据集上，对抗样本问题可以被认为**“基本解决”**了（至少针对 $l_\infty$ 范数）。

#### 2. CIFAR10 的结果（重头戏）
*   **背景**：CIFAR10 是彩色自然图像，比 MNIST 难得多。在 Madry 之前，几乎没有模型能在强力白盒攻击下存活（准确率通常是 0% - 5%）。
*   **Adversarial Accuracy**：
    *   Madry 的 **Wide ResNet** 在面对 PGD-20 攻击时，准确率达到了 **45.8%**。
    *   **这看着不高？** 别忘了，这可是让攻击者竭尽全力去攻击的结果。在此之前这个数字是接近 0 的。把防御率从 0 提升到 46%，这是**从无到有**的质变。
    *   注：即便到了 2024 年，不使用额外数据（Generated Data），只用纯 CIFAR10 训练，State-of-the-art (SOTA) 的鲁棒性也就提到 50%-60% 左右。可见 Madry 这个 baseline 有多坚挺。

---

**(接下篇：Section 5 的后半部分，关于评估的各种花样和补充实验)**