这是一个非常棒的**元问题（Meta-question）**！

很多时候我们陷在复杂的公式里，反而忘了这一步最基础的逻辑。能问出这个问题，说明你在认真思考攻击的本质。

简单来说：**因为“Loss”代表了模型的“错误程度”。**

我们来看这个逻辑链条：

### 1. 什么是 Loss？（定义痛苦）
在深度学习里，Loss Function（损失函数，记为 $J$）衡量的是**“模型的预测结果”与“真实标签”之间的差距**。

*   **Loss 小** = 预测很准（比如你是猫，我预测你是猫的概率 99%）。
*   **Loss 大** = 预测很差（比如你是猫，我预测你是猫的概率只有 0.1%，或者我预测你是狗）。

### 2. 训练者 vs. 攻击者（一场拔河比赛）

想象你们在一个山谷地形图上。

#### A. 你的角色：模型训练者 (The Trainer)
*   **目标：** 你希望模型越准越好。
*   **手段：** 你想让 Loss 变**小**。
*   **动作：** **梯度下降 (Gradient Descent)**。
    *   你看着 Loss 的“下坡”方向，调整模型的**权重（Weights, $\theta$）**，让模型往谷底走。

#### B. 他的角色：对抗攻击者 (The Attacker)
*   **目标：** 他希望模型越蠢越好，希望模型犯错。
*   **手段：** 他想让 Loss 变**大**。
*   **动作：** **梯度上升 (Gradient Ascent)**。
    *   Goodfellow 的 FGSM 就是在做这个。
    *   **关键区别：** 攻击者**不能改模型的权重**（那是作弊，而且通常没权限）。攻击者只能**改输入图片（Input, $x$）**。
    *   他看着 Loss 的“上坡”方向（梯度的方向），把图片 $x$ 往山上推一把。

### 3. 数学直觉 (Cross-Entropy Loss)

以最常用的**交叉熵损失 (Cross-Entropy Loss)** 为例：
假设真实标签 $y=1$（是猫），模型的预测是 $p$（是猫的概率）。

Loss 的公式大概长这样：
$$ J = - \log(p) $$

*   **正常情况：** 模型预测 $p=0.99$（很自信是猫）。
    *   $J = -\log(0.99) \approx 0.01$。
    *   **Loss 很小。**

*   **攻击目标：** 我想让你把那只猫认错（比如认成狗，或者至少“不认为是猫”）。
    *   这意味着我想让 $p$ 变小（比如变成 0.01）。
    *   如果 $p=0.01$，那么 $J = -\log(0.01) \approx 4.6$。
    *   **Loss 变得很大！**

**结论：**
**最大化 Loss，就是在强迫模型把原本属于“正确类”的概率压低，从而导致错误分类。**

### 4. 你的 GAN 科研视角

既然你对 GAN 感兴趣，这个逻辑在 GAN 里是一模一样的，叫做**极小极大博弈 (Min-Max Game)**：

$$ \min_G \max_D V(D, G) $$

*   **判别器 (D) 想最大化自己的准确率**（也就是最小化自己的 Loss，或者说最大化识别出真假的概率）。
*   **生成器 (G) 想干什么？**
    *   G 想**攻击** D。
    *   G 想生成一张假图，让 D 认不出来。
    *   也就是说，G 的目标是**最大化 D 的 Loss**（让 D 犯错）。

所以，**对抗攻击（Adversarial Attack）** 的本质就是：
**我是考官（Attacker），你是学生（Model）。我的目标是出最偏最难的题（Adversarial Example），让你的分数（Accuracy）最低，也就是让你做错题的程度（Loss）最大化。**

这就是为什么要“最大化 Loss”。