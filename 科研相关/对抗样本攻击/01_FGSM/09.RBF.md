第七部分 **"7. DIFFERENT KINDS OF MODEL CAPACITY"** 的思维深度非常棒。在这里，Goodfellow 讨论了一个看起来很矛盾的现象，并给出了基于“容量（Capacity）”的解释。

这一章的核心冲突是：
*   我们通常认为：**可以被攻击** = **模型太笨（Capacity低/欠拟合）**。
*   但事实是：**RBF 网络（一种简单的非线性模型）** 看起来比 **深度线性网络** 更抗打，但这真的意味着它更好吗？

Goodfellow 在这里引入了 **精确率（Precision）** 和 **召回率（Recall）** 的权衡来解释这个问题。

---

### 一、 两种模型，两种世界观

为了搞清楚为什么不同模型对攻击反应不同，作者对比了两类模型：

#### 1. 线性模型家族 (RBF 的对立面)
*   **代表：** ReLU 网络、Maxout 网络、FGSM 攻击得逞的那些模型。
*   **行为模式：** **“广撒网” (High Recall)**。
    *   它们使用线性平面来切割空间。
    *   只要在这个平面的一侧，哪怕离得十万八千里远（从来没见过的数据），它也会自信地说：“这是猫”。
*   **优点：** 泛化能力强，没见过的样本也能猜对。
*   **缺点：** 容易被骗。在离数据很远的地方（对抗样本），它依然自信满满地瞎猜。

#### 2. RBF 网络 (Radial Basis Function Networks)
*   **公式：** $p(y=1|x) = \exp((x-\mu)^T \beta (x-\mu))$。
    *   这是一个高斯钟形曲线。只有当输入 $x$ 非常靠近中心 $\mu$ 时，输出才高。
*   **行为模式：** **“只信眼前” (High Precision)**。
    *   它就像是一个只认死理的人。只有当你和它记忆中的模板 $\mu$ 长得几乎一模一样时，它才说是猫。
    *   稍微偏离一点点，它的响应值就迅速衰减归零。
*   **优点：** **天然免疫对抗样本！**
    *   如果你用 FGSM 把图片推远一点（变成对抗样本），RBF 网络会说：“这东西我看都不看，置信度为 0，我不知道这是啥。”而不是像线性模型那样高喊：“这是长臂猿！”
    *   **数据支持：** 论文中 RBF 网络的置信度在对抗样本上只有 1.2%（非常困惑），而 Maxout 网络高达 97.6%（盲目自信）。

### 二、 为什么我们不全都用 RBF？（Trade-off）

既然 RBF 这么安全，为什么现在没人用它做 ImageNet？
这就回到了 **容量（Capacity）** 的问题。

1.  **没有泛化能力：**
    RBF 是一一对应的“模板匹配”。如果你把一只猫稍微旋转一下，或者换个光照，它就不在这个“高斯圆”里了，RBF 就认不出来了。这在现实世界（高维变换多）是灾难性的。
2.  **维度灾难：**
    要覆盖高维空间里的所有猫的形态，你需要无穷多个 RBF 神经元（$\mu$）来铺满整个流形。这在计算上是不可能的。

### 三、 核心结论：精确率 vs 召回率

Goodfellow 用这两个概念总结了这次对比：

*   **线性单元（Linear Units）：** 为了追求 **高召回率（High Recall）**，敢于对未知区域做推断，代价就是**低精确率（Low Precision）**，容易在未知区域出错（被攻击）。
*   **RBF 单元：** 追求 **高精确率（High Precision）**，只对极度确定的点响应，代价就是 **低召回率（Low Recall）**，稍微变一点就不认了。

### 四、 寻找中间路线：二次单元？

作者最后尝试探索一种中间方案：
既然线性太容易被骗，RBF 又太死板，能不能用 **二次单元（Quadratic Units）**？
*   想法是引入一些非线性，但又不至于像 RBF 那么局限。
*   **结果（悲观）：** 很难训练。作者尝试了训练深层 RBF 或二次网络，但在高维数据上很难收敛。

### 五、 给 GAN 科研的启示

读完这一章，你会明白为什么现在的深度学习（包括 GAN）依然坚持使用 ReLU（线性）：

1.  **不仅仅是为了好训练，更是为了泛化。** 我们需要模型有一定的模糊推理能力，不能是个死记硬背的 RBF。
2.  **安全性是泛化的代价。** 这个 Trade-off 告诉我们，不可能仅仅通过换一个激活函数就“既要还要”。
3.  **GAN 的判别器 (Discriminator)：**
    目前的 GAN 判别器大多也是 ReLU 这种线性家族。所以，GAN 的判别器同样容易被对抗样本欺骗！这引出了一个研究方向：**能不能攻击 GAN 的判别器，让 GAN 训练崩溃？** 或者 **用 GAN 生成的样本去探测判别器的盲区？**

**一句话总结第七章：**
**“对抗样本不是因为模型‘太笨’（容量小），而是因为模型为了学会‘举一反三’（泛化），不得不给未知领域赋予了过于简单的线性假设。RBF 虽然安全，但它只是‘死记硬背’，没有实用价值。我们要找的是一种既能泛化，又不那么容易被线性欺骗的新路径。”**