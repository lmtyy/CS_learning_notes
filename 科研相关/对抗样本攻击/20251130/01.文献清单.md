下面给你挑出 10 篇高质量论文（优先包含中文综述；混合基础经典与近 3 年的最新工作）。我把每篇标注为：综述 / 基础（经典）/ 近三年（最新），并给出一句重点说明与文献链接。你可以先按这个清单阅读：先看 综述 + 基础，接着读近三年的最新工作以把握前沿。

直接清单（按优先阅读顺序建议）：

1) 面向网络空间防御的对抗机器学习研究综述（中文，综述, 2022）— 系统回顾了对抗样本、投毒/规避攻击、常见防御与评价，适合作为入门与国内视角的全面综述。[详读建议：威胁模型与对抗训练章节][^1]  
2) 面向图像数据的对抗样本检测与防御技术综述（中文，综述, 2022, 计算机研究与发展）— 聚焦图像领域的检测/防御方法分类、优缺点比较，帮助理解图像任务上的防御谱系与评估陷阱（如梯度掩盖问题）[^2].  
3) 图像对抗样本防御技术研究综述（中文，综述/综览，若干期刊与会议汇总/综述PDF）— 可作为补充综述，覆盖更多检测/预处理/对抗训练与可证方法比较[^3].

4) Intriguing properties of neural networks — Szegedy et al., 2014（基础/经典）— 首次系统发现对抗样本现象并提出最早的例子，奠定领域起点（推荐先读此文以理解问题由来）[^4].  
5) Explaining and Harnessing Adversarial Examples — Goodfellow et al., 2015（基础/经典）— 提出 FGSM 并从线性近似角度解释对抗性，是理解基线攻击的核心文章[^5].  
6) Towards Evaluating the Robustness of Neural Networks — Carlini & Wagner, 2017（基础/经典）— 提出强攻击（CW）并拆解若干防御的失败案例，对评估和攻击设计非常重要[^6].  
7) Towards Deep Learning Models Resistant to Adversarial Attacks — Madry et al., 2018（基础/经典）— 提出用 PGD 的对抗训练作为强基线（“PGD-based adversarial training”），是防御研究的基石之一[^7].

8) MF-CLIP: Leveraging CLIP as Surrogate Models for No-box Adversarial Attacks — Zhang et al., 2023（近三年/最新）— 探讨将大型视觉语言模型（如 CLIP）用作无查询/无盒（no-box）攻击的替代模型以提升迁移性，适合关注多模态/大模型场景的对抗研究[^8].  
9) Revisiting the Adversarial Robustness of Vision-Language Models — (arXiv, 2024)（近三年/最新）— 系统分析视觉-语言模型在对抗扰动下的鲁棒性与新攻击面，适合了解 VLM（如 CLIP、align 模型）在对抗安全方面的新挑战[^9].  
10) Test-time Counterattacks towards Zero-shot Adversarial Robustness of CLIP — CVPR 2025 / arXiv (2025)（近三年/最新）— 提出测试时（training-free）防护/反击策略以提升 CLIP 在零样本/下游任务上的鲁棒性，属于最新进展（若要研究防御策略或实时防护非常值得读）[^10].

注：第 1–3 项为中文综述，适合作为快速建立中文语境下的全局认知；第 4–7 为领域经典基石，建议逐篇读并实现其中的简单攻击（FGSM、PGD、CW）以加深理解；第 8–10 为近三年（2023–2025）关于多模态/CLIP/视觉语言模型对抗性的最新研究，反映当前研究热点（迁移性、多模态攻击与训练/测试时防御）。

我把每篇文献的可访问链接列在下面（按上面序号对应），你可以点击下载 PDF 或在线阅读：

参考与下载链接：
[^1]: https://www.aas.net.cn/cn/article/doi/10.16383/j.aas.c210089?viewType=HTML  
[^2]: https://crad.ict.ac.cn/article/cstr/32373.14.issn1000-1239.20200777  
[^3]: http://znaq.ijournals.cn/znaq/article/html/20240628002?st=article_issue  
[^4]: https://arxiv.org/abs/1312.6199  
[^5]: https://arxiv.org/abs/1412.6572  
[^6]: https://arxiv.org/abs/1608.04644  
[^7]: https://arxiv.org/abs/1706.06083  
[^8]: https://arxiv.org/abs/2307.06608  
[^9]: https://arxiv.org/abs/2404.19287  
[^10]: https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_CLIP_is_Strong_Enough_to_Fight_Back_Test-time_Counterattacks_towards_CVPR_2025_paper.pdf

说明与后续可选项
- 如果你需要，我可以把上面每篇的“3 分钟速读要点”做成一页（包括：主要贡献、使用的数据集/任务、关键公式/算法、实现提示、复现实验要点）。  
- 我也可以直接给出在 CIFAR-10 / CIFAR-100 上实现 FGSM、PGD、CW、以及用 AutoAttack 评估的 PyTorch 实验脚本，方便你动手复现（导师通常喜欢能跑出结果的实验）。  
- 若你希望我把“中文综述”中的章节（比如对抗训练、检测、可证方法）摘录要点并对比优缺点，我也可以把其表格化便于写文献综述。

你想先要哪一项？（A）每篇 3 分钟要点摘要；（B）立刻给出一个可运行的 PyTorch 对抗攻击/评估脚本；（C）把这 10 篇按“阅读顺序 + 每篇预计阅读时间”排好供你逐周学习。